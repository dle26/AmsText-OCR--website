{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Line segment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg4aWydchsZq",
        "colab_type": "text"
      },
      "source": [
        "PAGE EXTRACTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaoImtyEYiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8a0f5642-c1be-4255-a5ff-eb5e79b533c5"
      },
      "source": [
        "!git clone https://github.com/dhlab-epfl/dhSegment.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dhSegment'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 2530 (delta 46), reused 106 (delta 34), pack-reused 2395\u001b[K\n",
            "Receiving objects: 100% (2530/2530), 6.06 MiB | 8.88 MiB/s, done.\n",
            "Resolving deltas: 100% (1620/1620), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU_PExyVTdSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "daaaf4c8-0538-450a-a19a-1f59bad069f9"
      },
      "source": [
        "!pip install git+https://github.com/dhlab-epfl/dhSegment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/dhlab-epfl/dhSegment\n",
            "  Cloning https://github.com/dhlab-epfl/dhSegment to /tmp/pip-req-build-zre6ycw2\n",
            "  Running command git clone -q https://github.com/dhlab-epfl/dhSegment /tmp/pip-req-build-zre6ycw2\n",
            "Requirement already satisfied (use --upgrade to upgrade): dh-segment==0.6.0 from git+https://github.com/dhlab-epfl/dhSegment in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: imageio>=2.5 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (2.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (1.0.5)\n",
            "Requirement already satisfied: shapely>=1.6.4 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (1.7.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (0.16.2)\n",
            "Requirement already satisfied: opencv-python>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: sacred==0.7.4 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (0.7.4)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from dh-segment==0.6.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio>=2.5->dh-segment==0.6.0) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio>=2.5->dh-segment==0.6.0) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->dh-segment==0.6.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->dh-segment==0.6.0) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.3->dh-segment==0.6.0) (0.15.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.3->dh-segment==0.6.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.15.0->dh-segment==0.6.0) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.15.0->dh-segment==0.6.0) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.15.0->dh-segment==0.6.0) (1.1.1)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.4->dh-segment==0.6.0) (1.12.1)\n",
            "Requirement already satisfied: jsonpickle<1.0,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.4->dh-segment==0.6.0) (0.9.6)\n",
            "Requirement already satisfied: docopt<1.0,>=0.3 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.4->dh-segment==0.6.0) (0.6.2)\n",
            "Requirement already satisfied: py-cpuinfo>=4.0 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.4->dh-segment==0.6.0) (6.0.0)\n",
            "Requirement already satisfied: munch<3.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.4->dh-segment==0.6.0) (2.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->dh-segment==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->dh-segment==0.6.0) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->dh-segment==0.6.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->dh-segment==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->dh-segment==0.6.0) (1.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->dh-segment==0.6.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->dh-segment==0.6.0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->dh-segment==0.6.0) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.15.0->dh-segment==0.6.0) (4.4.2)\n",
            "Building wheels for collected packages: dh-segment\n",
            "  Building wheel for dh-segment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dh-segment: filename=dh_segment-0.6.0-cp36-none-any.whl size=83475 sha256=871051e50d4cf346786794ac3ee4acd2add6efc165f053cb0670f7b94c915342\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iq2jqayu/wheels/28/a4/f9/fc3442461c38e351b0b3cf60c70d2cd398f9cb9d242c20964b\n",
            "Successfully built dh-segment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw5z6qX4ZG1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "45bc64db-1e7d-4658-b720-0399cfd938e7"
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 24kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.30.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (47.3.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LavELU3QEa91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/dhlab-epfl/dhSegment/releases/download/v0.2/pages.zip\n",
        "!unzip pages.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7-sI0qXJuhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "ba2bbb83-b82a-4c3c-8128-2acfdc7d29ea"
      },
      "source": [
        "!wget https://github.com/dhlab-epfl/dhSegment/releases/download/v0.2/model.zip\n",
        "!unzip model.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-01 03:30:50--  https://github.com/dhlab-epfl/dhSegment/releases/download/v0.2/model.zip\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/97129580/76389bfc-38d2-11e8-9786-94e2a43f100f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200701%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200701T033050Z&X-Amz-Expires=300&X-Amz-Signature=5631f55a862a082cd521f5617cdf22cf970b765b78e2f403ec52099ca997cd38&X-Amz-SignedHeaders=host&actor_id=0&repo_id=97129580&response-content-disposition=attachment%3B%20filename%3Dmodel.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-01 03:30:50--  https://github-production-release-asset-2e65be.s3.amazonaws.com/97129580/76389bfc-38d2-11e8-9786-94e2a43f100f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200701%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200701T033050Z&X-Amz-Expires=300&X-Amz-Signature=5631f55a862a082cd521f5617cdf22cf970b765b78e2f403ec52099ca997cd38&X-Amz-SignedHeaders=host&actor_id=0&repo_id=97129580&response-content-disposition=attachment%3B%20filename%3Dmodel.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.110.35\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.110.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122459677 (117M) [application/octet-stream]\n",
            "Saving to: ‘model.zip’\n",
            "\n",
            "model.zip           100%[===================>] 116.79M  31.6MB/s    in 4.2s    \n",
            "\n",
            "2020-07-01 03:30:55 (27.8 MB/s) - ‘model.zip’ saved [122459677/122459677]\n",
            "\n",
            "Archive:  model.zip\n",
            "   creating: model/\n",
            "  inflating: model/saved_model.pb    \n",
            "   creating: model/variables/\n",
            "  inflating: model/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/variables/variables.index  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghWijhUoew1r",
        "colab_type": "text"
      },
      "source": [
        "Move demo to dhSegment and model to demo.\n",
        "Create file test inside dhSegment, images inside test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-iIFq-rVLMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "be927ee1-c4de-4d3f-f06c-63387360f7de"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from imageio import imread, imsave\n",
        "from tqdm import tqdm\n",
        "\n",
        "from dh_segment.io import PAGE\n",
        "from dh_segment.inference import LoadedModel\n",
        "from dh_segment.post_processing import boxes_detection, binarization\n",
        "\n",
        "# To output results in PAGE XML format (http://www.primaresearch.org/schema/PAGE/gts/pagecontent/2013-07-15/)\n",
        "PAGE_XML_DIR = './page_xml'\n",
        "\n",
        "\n",
        "def page_make_binary_mask(probs: np.ndarray, threshold: float=-1) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the binary mask of the detected Page from the probabilities outputed by network\n",
        "    :param probs: array with values in range [0, 1]\n",
        "    :param threshold: threshold between [0 and 1], if negative Otsu's adaptive threshold will be used\n",
        "    :return: binary mask\n",
        "    \"\"\"\n",
        "\n",
        "    mask = binarization.thresholding(probs, threshold)\n",
        "    mask = binarization.cleaning_binary(mask, kernel_size=5)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def format_quad_to_string(quad):\n",
        "    \"\"\"\n",
        "    Formats the corner points into a string.\n",
        "    :param quad: coordinates of the quadrilateral\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    s = ''\n",
        "    for corner in quad:\n",
        "        s += '{},{},'.format(corner[0], corner[1])\n",
        "    return s[:-1]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # If the model has been trained load the model, otherwise use the given model\n",
        "    model_dir = '/content/dhSegment/demo/page_model/export'\n",
        "    if not os.path.exists(model_dir):\n",
        "        model_dir = '/content/dhSegment/demo/model'\n",
        "\n",
        "    input_files = glob('/content/dhSegment/demo/test_a1/images/*')\n",
        "\n",
        "    output_dir = '/content/dhSegment/demo/processed_images'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    # PAGE XML format output\n",
        "    output_pagexml_dir = os.path.join(output_dir, PAGE_XML_DIR)\n",
        "    os.makedirs(output_pagexml_dir, exist_ok=True)\n",
        "\n",
        "    # Store coordinates of page in a .txt file\n",
        "    txt_coordinates = ''\n",
        "\n",
        "    with tf.Session():  # Start a tensorflow session\n",
        "        # Load the model\n",
        "        m = LoadedModel(model_dir, predict_mode='filename')\n",
        "\n",
        "        for filename in tqdm(input_files, desc='Processed files'):\n",
        "            # For each image, predict each pixel's label\n",
        "            prediction_outputs = m.predict(filename)\n",
        "            probs = prediction_outputs['probs'][0]\n",
        "            original_shape = prediction_outputs['original_shape']\n",
        "            probs = probs[:, :, 1]  # Take only class '1' (class 0 is the background, class 1 is the page)\n",
        "            probs = probs / np.max(probs)  # Normalize to be in [0, 1]\n",
        "\n",
        "            # Binarize the predictions\n",
        "            page_bin = page_make_binary_mask(probs)\n",
        "\n",
        "            # Upscale to have full resolution image (cv2 uses (w,h) and not (h,w) for giving shapes)\n",
        "            bin_upscaled = cv2.resize(page_bin.astype(np.uint8, copy=False),\n",
        "                                      tuple(original_shape[::-1]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            # Find quadrilateral enclosing the page\n",
        "            pred_page_coords = boxes_detection.find_boxes(bin_upscaled.astype(np.uint8, copy=False),\n",
        "                                                          mode='min_rectangle', min_area=0.2, n_max_boxes=1)\n",
        "\n",
        "            # Draw page box on original image and export it. Add also box coordinates to the txt file\n",
        "            original_img = imread(filename, pilmode='RGB')\n",
        "            if pred_page_coords is not None:\n",
        "                cv2.polylines(original_img, [pred_page_coords[:, None, :]], True, (0, 0, 255), thickness=5)\n",
        "                # Write corners points into a .txt file\n",
        "                txt_coordinates += '{},{}\\n'.format(filename, format_quad_to_string(pred_page_coords))\n",
        "\n",
        "                # Create page region and XML file\n",
        "                page_border = PAGE.Border(coords=PAGE.Point.cv2_to_point_list(pred_page_coords[:, None, :]))\n",
        "            else:\n",
        "                print('No box found in {}'.format(filename))\n",
        "                page_border = PAGE.Border()\n",
        "\n",
        "            basename = os.path.basename(filename).split('.')[0]\n",
        "            imsave(os.path.join(output_dir, '{}_boxes.jpg'.format(basename)), original_img)\n",
        "\n",
        "            page_xml = PAGE.Page(image_filename=filename, image_width=original_shape[1], image_height=original_shape[0],\n",
        "                                 page_border=page_border)\n",
        "            xml_filename = os.path.join(output_pagexml_dir, '{}.xml'.format(basename))\n",
        "            page_xml.write_to_file(xml_filename, creator_name='PageExtractor')\n",
        "\n",
        "    # Save txt file\n",
        "    with open(os.path.join(output_dir, 'pages.txt'), 'w') as f:\n",
        "        f.write(txt_coordinates)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/dhSegment/demo/model\n",
            "INFO:tensorflow:Restoring parameters from /content/dhSegment/demo/model/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processed files: 100%|██████████| 1/1 [00:07<00:00,  7.40s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOC7gf-8X6fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}