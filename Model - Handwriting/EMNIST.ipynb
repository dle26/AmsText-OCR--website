{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0521 13:11:52.923036 140109005711168 deprecation_wrapper.py:118] From /usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py:99: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0521 13:11:52.924261 140109005711168 deprecation_wrapper.py:118] From /usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py:99: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.\n",
      "\n",
      "W0521 13:11:52.925293 140109005711168 deprecation_wrapper.py:118] From /usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py:99: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead.\n",
      "\n",
      "W0521 13:11:52.926069 140109005711168 deprecation_wrapper.py:118] From /usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py:99: The name tf.CXX11_ABI_FLAG is deprecated. Please use tf.sysconfig.CXX11_ABI_FLAG instead.\n",
      "\n",
      "W0521 13:11:52.926953 140109005711168 deprecation_wrapper.py:118] From /usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py:99: The name tf.ConditionalAccumulator is deprecated. Please use tf.compat.v1.ConditionalAccumulator instead.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "#from emnist import extract_training_samples\n",
    "#from emnist import extract_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fg import \n",
    "import keras\n",
    "import numpy as np\n",
    "from mlxtend.data import loadlocal_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = loadlocal_mnist(\n",
    "        images_path='./gzip/emnist-balanced-train-images-idx3-ubyte', \n",
    "        labels_path='./gzip/emnist-balanced-train-labels-idx1-ubyte')\n",
    "x_test, y_test = loadlocal_mnist(\n",
    "        images_path='./gzip/emnist-balanced-test-images-idx3-ubyte', \n",
    "        labels_path='./gzip/emnist-balanced-test-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112800, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 784,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code of the data preparation belongs to https://github.com/shubhammor0403/EMNIST/blob/master/modeltrain.ipynb\n",
    "def resh(ipar):\n",
    "    opar = []\n",
    "    for image in ipar:\n",
    "        opar.append(image.reshape(-1))\n",
    "    return np.asarray(opar)\n",
    "\n",
    "train_images = x_train.astype('float32')\n",
    "test_images = x_test.astype('float32')\n",
    "\n",
    "train_images = resh(train_images)\n",
    "test_images = resh(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 47)                24111     \n",
      "=================================================================\n",
      "Total params: 9,462,639\n",
      "Trainable params: 9,462,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 47)                24111     \n",
      "=================================================================\n",
      "Total params: 9,462,639\n",
      "Trainable params: 9,462,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 112800 samples, validate on 18800 samples\n",
      "Epoch 1/20\n",
      "112800/112800 [==============================] - 38s 333us/sample - loss: 0.7165 - acc: 0.7762 - val_loss: 0.5441 - val_acc: 0.8256\n",
      "Epoch 2/20\n",
      "112800/112800 [==============================] - 38s 333us/sample - loss: 0.4095 - acc: 0.8589 - val_loss: 0.4424 - val_acc: 0.8514\n",
      "Epoch 3/20\n",
      "112800/112800 [==============================] - 38s 340us/sample - loss: 0.3436 - acc: 0.8797 - val_loss: 0.4389 - val_acc: 0.8597\n",
      "Epoch 4/20\n",
      "112800/112800 [==============================] - 39s 342us/sample - loss: 0.3047 - acc: 0.8906 - val_loss: 0.4410 - val_acc: 0.8639\n",
      "Epoch 5/20\n",
      "112800/112800 [==============================] - 38s 340us/sample - loss: 0.2801 - acc: 0.8992 - val_loss: 0.4557 - val_acc: 0.8551\n",
      "Epoch 6/20\n",
      "112800/112800 [==============================] - 38s 340us/sample - loss: 0.2626 - acc: 0.9050 - val_loss: 0.4441 - val_acc: 0.8548\n",
      "Epoch 7/20\n",
      "112800/112800 [==============================] - 39s 347us/sample - loss: 0.2500 - acc: 0.9095 - val_loss: 0.4715 - val_acc: 0.8676\n",
      "Epoch 8/20\n",
      "112800/112800 [==============================] - 39s 346us/sample - loss: 0.2412 - acc: 0.9127 - val_loss: 0.4634 - val_acc: 0.8629\n",
      "Epoch 9/20\n",
      "112800/112800 [==============================] - 37s 328us/sample - loss: 0.2306 - acc: 0.9164 - val_loss: 0.4665 - val_acc: 0.8649\n",
      "Epoch 10/20\n",
      "112800/112800 [==============================] - 27s 242us/sample - loss: 0.2228 - acc: 0.9191 - val_loss: 0.5025 - val_acc: 0.8606\n",
      "Epoch 11/20\n",
      "112800/112800 [==============================] - 17s 147us/sample - loss: 0.2142 - acc: 0.9224 - val_loss: 0.4903 - val_acc: 0.8507\n",
      "Epoch 12/20\n",
      "112800/112800 [==============================] - 16s 144us/sample - loss: 0.2067 - acc: 0.9247 - val_loss: 0.5889 - val_acc: 0.8644\n",
      "Epoch 13/20\n",
      "112800/112800 [==============================] - 16s 146us/sample - loss: 0.1993 - acc: 0.9265 - val_loss: 0.5146 - val_acc: 0.8589\n",
      "Epoch 14/20\n",
      "112800/112800 [==============================] - 17s 150us/sample - loss: 0.1940 - acc: 0.9283 - val_loss: 0.6436 - val_acc: 0.8637\n",
      "Epoch 15/20\n",
      "112800/112800 [==============================] - 17s 151us/sample - loss: 0.1884 - acc: 0.9315 - val_loss: 0.8366 - val_acc: 0.8616\n",
      "Epoch 16/20\n",
      "112800/112800 [==============================] - 17s 150us/sample - loss: 0.1845 - acc: 0.9328 - val_loss: 0.6988 - val_acc: 0.8634\n",
      "Epoch 17/20\n",
      "112800/112800 [==============================] - 17s 151us/sample - loss: 0.1804 - acc: 0.9342 - val_loss: 0.6242 - val_acc: 0.8634\n",
      "Epoch 18/20\n",
      "112800/112800 [==============================] - 17s 150us/sample - loss: 0.1754 - acc: 0.9358 - val_loss: 0.5332 - val_acc: 0.8559\n",
      "Epoch 19/20\n",
      "112800/112800 [==============================] - 17s 149us/sample - loss: 0.1751 - acc: 0.9369 - val_loss: 0.6884 - val_acc: 0.8631\n",
      "Epoch 20/20\n",
      "112800/112800 [==============================] - 17s 149us/sample - loss: 0.1686 - acc: 0.9380 - val_loss: 0.7970 - val_acc: 0.8648\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Reshape((28,28,1), input_shape=(784,)),\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)), #have not run it last time\n",
    "    #tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu'),\n",
    "    #tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # # The third convolution\n",
    "    # tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # # The fourth convolution\n",
    "    # tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(47, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "history = model.fit(train_images,y_train,validation_data=(test_images, y_test), batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EMNIST.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
